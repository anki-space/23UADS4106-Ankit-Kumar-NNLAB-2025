{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tejzdxH0fWJ"
      },
      "source": [
        "# **Experiment 5:Implementation of CNN using Keras Library**\n",
        "\n",
        "## **1.Objective**\n",
        "WAP to train and evaluate a convolutional neural network using Keras Library to classify MNIST fashion dataset. Demonstrate the effect of filter size, regularization, batch size and optimization algorithm on model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNlShMOG2ts1"
      },
      "source": [
        "### **2. Description of the Model**\n",
        "\n",
        "We implement a CNN architecture with:\n",
        "\n",
        "- Two convolutional layers (Conv2D) with ReLU activation.\n",
        "\n",
        "- Max-pooling layers (MaxPooling2D) to reduce spatial dimensions.\n",
        "\n",
        "- Flatten layer to convert feature maps into a 1D vector.\n",
        "\n",
        "- Fully connected dense layer with 128 neurons and ReLU activation.\n",
        "\n",
        "- Output layer with softmax activation for multi-class classification.\n",
        "\n",
        "The model is trained for **15 epochs** using different configurations for hyperparameter tuning of:\n",
        "\n",
        "- **Filter Sizes**: (3 x 3) ,(5 x 5)\n",
        "\n",
        "- **Regularization**: None and 0.01 (L2 Regularization)\n",
        "\n",
        "- **Batch Sizes**: 128 and 256\n",
        "\n",
        "- **Optimizers**: Adam and SGD\n",
        "\n",
        "Total of 16 different configuration are trained to find the optimal configuration with significant accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfU1Qm5l408T"
      },
      "source": [
        "### **3. Python Implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqo6GLflbQq4",
        "outputId": "a9860c74-7409-4b07-96d3-f1e5731d0507"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2ml4mJHYa7WI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, regularizers\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.backend import clear_session\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcotvoiGaxlk",
        "outputId": "c5ed9820-ea4c-4176-91b3-17f7f7aa8b44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Enable eager execution\n",
        "tf.config.run_functions_eagerly(True)\n",
        "tf.data.experimental.enable_debug_mode()\n",
        "\n",
        "# Load Fashion MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Normalize and reshape\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "\n",
        "# Store results for plotting\n",
        "results = []\n",
        "accuracy_curves = {}\n",
        "loss_curves = {}\n",
        "confusion_matrices = {}\n",
        "\n",
        "# Function to build the CNN model\n",
        "def build_model(filter_size, reg=None):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(32, filter_size, activation='relu',\n",
        "                      kernel_regularizer=regularizers.l2(reg) if reg else None),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, filter_size, activation='relu',\n",
        "                      kernel_regularizer=regularizers.l2(reg) if reg else None),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu',\n",
        "                     kernel_regularizer=regularizers.l2(reg) if reg else None),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "alTGoGwsa9jU"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "filter_sizes = [(3, 3), (5, 5)]\n",
        "regularizations = [None, 0.01]\n",
        "batch_sizes = [128, 256]\n",
        "optimizers = {\n",
        "    'Adam': Adam,  # Use class, not instance\n",
        "   'SGD': SGD,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IetRhFGUcG2o"
      },
      "outputs": [],
      "source": [
        "# Define the root directory for saving files\n",
        "ROOT_DIR = \"/content/drive/MyDrive/MBM_NN_LAB_6TH_SEM/EXP_5\"\n",
        "\n",
        "# Create required subdirectories\n",
        "os.makedirs(os.path.join(ROOT_DIR, \"accuracy_curves\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(ROOT_DIR, \"loss_curves\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(ROOT_DIR, \"confusion_matrices\"), exist_ok=True)\n",
        "\n",
        "# Initialize a list to store tabular results\n",
        "results_table = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGOCPqkscO9G",
        "outputId": "2909d104-d71e-4744-b690-f8a81b81ecbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training model with Filter_size=(3, 3) Regularization=None Batch=128 Optimizer=Adam\n",
            "Epoch 1/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 122ms/step - accuracy: 0.7241 - loss: 0.7825 - val_accuracy: 0.8587 - val_loss: 0.3985\n",
            "Epoch 2/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 121ms/step - accuracy: 0.8719 - loss: 0.3588 - val_accuracy: 0.8815 - val_loss: 0.3377\n",
            "Epoch 3/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 121ms/step - accuracy: 0.8908 - loss: 0.3019 - val_accuracy: 0.8952 - val_loss: 0.2918\n",
            "Epoch 4/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 121ms/step - accuracy: 0.9053 - loss: 0.2584 - val_accuracy: 0.8912 - val_loss: 0.2973\n",
            "Epoch 5/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 123ms/step - accuracy: 0.9091 - loss: 0.2456 - val_accuracy: 0.9044 - val_loss: 0.2674\n",
            "Epoch 6/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 122ms/step - accuracy: 0.9183 - loss: 0.2194 - val_accuracy: 0.9050 - val_loss: 0.2610\n",
            "Epoch 7/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 123ms/step - accuracy: 0.9218 - loss: 0.2103 - val_accuracy: 0.9051 - val_loss: 0.2625\n",
            "Epoch 8/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.9321 - loss: 0.1865 - val_accuracy: 0.9048 - val_loss: 0.2712\n",
            "Epoch 9/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.9375 - loss: 0.1741 - val_accuracy: 0.9130 - val_loss: 0.2481\n",
            "Epoch 10/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 121ms/step - accuracy: 0.9423 - loss: 0.1584 - val_accuracy: 0.9120 - val_loss: 0.2574\n",
            "Epoch 11/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.9461 - loss: 0.1444 - val_accuracy: 0.9162 - val_loss: 0.2549\n",
            "Epoch 12/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 119ms/step - accuracy: 0.9517 - loss: 0.1352 - val_accuracy: 0.9035 - val_loss: 0.2913\n",
            "Epoch 13/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 121ms/step - accuracy: 0.9557 - loss: 0.1207 - val_accuracy: 0.9154 - val_loss: 0.2530\n",
            "Epoch 14/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.9600 - loss: 0.1099 - val_accuracy: 0.9157 - val_loss: 0.2528\n",
            "Epoch 15/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.9643 - loss: 0.0986 - val_accuracy: 0.9167 - val_loss: 0.2637\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
            "Test Accuracy: 0.9167, Training Time: 851.03 sec\n",
            "\n",
            "Training model with Filter_size=(3, 3) Regularization=None Batch=128 Optimizer=SGD\n",
            "Epoch 1/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 92ms/step - accuracy: 0.3789 - loss: 1.7905 - val_accuracy: 0.6734 - val_loss: 0.8504\n",
            "Epoch 2/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.7078 - loss: 0.7986 - val_accuracy: 0.7420 - val_loss: 0.7155\n",
            "Epoch 3/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.7440 - loss: 0.6880 - val_accuracy: 0.7576 - val_loss: 0.6782\n",
            "Epoch 4/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.7677 - loss: 0.6226 - val_accuracy: 0.7659 - val_loss: 0.6250\n",
            "Epoch 5/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.7831 - loss: 0.5837 - val_accuracy: 0.7769 - val_loss: 0.5972\n",
            "Epoch 6/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.7979 - loss: 0.5415 - val_accuracy: 0.8072 - val_loss: 0.5341\n",
            "Epoch 7/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 91ms/step - accuracy: 0.8102 - loss: 0.5159 - val_accuracy: 0.7950 - val_loss: 0.5522\n",
            "Epoch 8/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.8166 - loss: 0.4952 - val_accuracy: 0.8243 - val_loss: 0.4921\n",
            "Epoch 9/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.8242 - loss: 0.4809 - val_accuracy: 0.8289 - val_loss: 0.4766\n",
            "Epoch 10/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.8294 - loss: 0.4673 - val_accuracy: 0.8309 - val_loss: 0.4684\n",
            "Epoch 11/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.8440 - loss: 0.4369 - val_accuracy: 0.8366 - val_loss: 0.4565\n",
            "Epoch 12/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.8456 - loss: 0.4287 - val_accuracy: 0.8421 - val_loss: 0.4376\n",
            "Epoch 13/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.8474 - loss: 0.4259 - val_accuracy: 0.8326 - val_loss: 0.4507\n",
            "Epoch 14/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.8516 - loss: 0.4108 - val_accuracy: 0.8496 - val_loss: 0.4289\n",
            "Epoch 15/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.8531 - loss: 0.4042 - val_accuracy: 0.8471 - val_loss: 0.4260\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
            "Test Accuracy: 0.8471, Training Time: 638.19 sec\n",
            "\n",
            "Training model with Filter_size=(3, 3) Regularization=None Batch=256 Optimizer=Adam\n",
            "Epoch 1/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 121ms/step - accuracy: 0.6694 - loss: 0.9538 - val_accuracy: 0.8361 - val_loss: 0.4545\n",
            "Epoch 2/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 119ms/step - accuracy: 0.8500 - loss: 0.4193 - val_accuracy: 0.8670 - val_loss: 0.3753\n",
            "Epoch 3/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 119ms/step - accuracy: 0.8744 - loss: 0.3538 - val_accuracy: 0.8639 - val_loss: 0.3728\n",
            "Epoch 4/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 119ms/step - accuracy: 0.8869 - loss: 0.3091 - val_accuracy: 0.8826 - val_loss: 0.3275\n",
            "Epoch 5/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 118ms/step - accuracy: 0.8966 - loss: 0.2859 - val_accuracy: 0.8864 - val_loss: 0.3193\n",
            "Epoch 6/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 141ms/step - accuracy: 0.8998 - loss: 0.2710 - val_accuracy: 0.8823 - val_loss: 0.3146\n",
            "Epoch 7/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 119ms/step - accuracy: 0.9048 - loss: 0.2613 - val_accuracy: 0.8982 - val_loss: 0.2831\n",
            "Epoch 8/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 120ms/step - accuracy: 0.9115 - loss: 0.2415 - val_accuracy: 0.8978 - val_loss: 0.2847\n",
            "Epoch 9/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 119ms/step - accuracy: 0.9138 - loss: 0.2331 - val_accuracy: 0.9024 - val_loss: 0.2696\n",
            "Epoch 10/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 121ms/step - accuracy: 0.9207 - loss: 0.2142 - val_accuracy: 0.8925 - val_loss: 0.3005\n",
            "Epoch 11/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 121ms/step - accuracy: 0.9256 - loss: 0.2068 - val_accuracy: 0.9025 - val_loss: 0.2667\n",
            "Epoch 12/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 120ms/step - accuracy: 0.9279 - loss: 0.1956 - val_accuracy: 0.9027 - val_loss: 0.2719\n",
            "Epoch 13/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 120ms/step - accuracy: 0.9307 - loss: 0.1857 - val_accuracy: 0.9058 - val_loss: 0.2661\n",
            "Epoch 14/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 119ms/step - accuracy: 0.9352 - loss: 0.1777 - val_accuracy: 0.9089 - val_loss: 0.2567\n",
            "Epoch 15/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 120ms/step - accuracy: 0.9396 - loss: 0.1636 - val_accuracy: 0.9050 - val_loss: 0.2658\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
            "Test Accuracy: 0.9050, Training Time: 427.83 sec\n",
            "\n",
            "Training model with Filter_size=(3, 3) Regularization=None Batch=256 Optimizer=SGD\n",
            "Epoch 1/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 93ms/step - accuracy: 0.2503 - loss: 2.1731 - val_accuracy: 0.6206 - val_loss: 1.0885\n",
            "Epoch 2/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 92ms/step - accuracy: 0.6717 - loss: 0.9442 - val_accuracy: 0.6968 - val_loss: 0.8234\n",
            "Epoch 3/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 90ms/step - accuracy: 0.7181 - loss: 0.7739 - val_accuracy: 0.7407 - val_loss: 0.7133\n",
            "Epoch 4/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 92ms/step - accuracy: 0.7381 - loss: 0.7052 - val_accuracy: 0.7094 - val_loss: 0.7928\n",
            "Epoch 5/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 92ms/step - accuracy: 0.7563 - loss: 0.6533 - val_accuracy: 0.7224 - val_loss: 0.7596\n",
            "Epoch 6/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 90ms/step - accuracy: 0.7713 - loss: 0.6209 - val_accuracy: 0.7767 - val_loss: 0.6008\n",
            "Epoch 7/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 92ms/step - accuracy: 0.7783 - loss: 0.5925 - val_accuracy: 0.7766 - val_loss: 0.6127\n",
            "Epoch 8/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 92ms/step - accuracy: 0.7930 - loss: 0.5627 - val_accuracy: 0.7799 - val_loss: 0.6076\n",
            "Epoch 9/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 90ms/step - accuracy: 0.7978 - loss: 0.5421 - val_accuracy: 0.7931 - val_loss: 0.5716\n",
            "Epoch 10/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 92ms/step - accuracy: 0.8066 - loss: 0.5228 - val_accuracy: 0.7532 - val_loss: 0.6144\n",
            "Epoch 11/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 92ms/step - accuracy: 0.8084 - loss: 0.5137 - val_accuracy: 0.8135 - val_loss: 0.5157\n",
            "Epoch 12/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 90ms/step - accuracy: 0.8178 - loss: 0.4961 - val_accuracy: 0.8089 - val_loss: 0.5304\n",
            "Epoch 13/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 92ms/step - accuracy: 0.8225 - loss: 0.4836 - val_accuracy: 0.7891 - val_loss: 0.5426\n",
            "Epoch 14/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 92ms/step - accuracy: 0.8226 - loss: 0.4802 - val_accuracy: 0.8054 - val_loss: 0.5337\n",
            "Epoch 15/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 90ms/step - accuracy: 0.8299 - loss: 0.4635 - val_accuracy: 0.8246 - val_loss: 0.4887\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
            "Test Accuracy: 0.8246, Training Time: 322.94 sec\n",
            "\n",
            "Training model with Filter_size=(3, 3) Regularization=0.01 Batch=128 Optimizer=Adam\n",
            "Epoch 1/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 128ms/step - accuracy: 0.6860 - loss: 1.7269 - val_accuracy: 0.7919 - val_loss: 0.7804\n",
            "Epoch 2/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 127ms/step - accuracy: 0.8083 - loss: 0.7303 - val_accuracy: 0.7871 - val_loss: 0.7385\n",
            "Epoch 3/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 129ms/step - accuracy: 0.8235 - loss: 0.6675 - val_accuracy: 0.8157 - val_loss: 0.6679\n",
            "Epoch 4/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 130ms/step - accuracy: 0.8288 - loss: 0.6403 - val_accuracy: 0.8143 - val_loss: 0.6840\n",
            "Epoch 5/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 129ms/step - accuracy: 0.8369 - loss: 0.6260 - val_accuracy: 0.8310 - val_loss: 0.6286\n",
            "Epoch 6/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 130ms/step - accuracy: 0.8417 - loss: 0.6009 - val_accuracy: 0.8263 - val_loss: 0.6410\n",
            "Epoch 7/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 130ms/step - accuracy: 0.8405 - loss: 0.6014 - val_accuracy: 0.8321 - val_loss: 0.6122\n",
            "Epoch 8/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 128ms/step - accuracy: 0.8473 - loss: 0.5840 - val_accuracy: 0.8393 - val_loss: 0.6017\n",
            "Epoch 9/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 128ms/step - accuracy: 0.8481 - loss: 0.5794 - val_accuracy: 0.8461 - val_loss: 0.5833\n",
            "Epoch 10/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 128ms/step - accuracy: 0.8512 - loss: 0.5639 - val_accuracy: 0.8471 - val_loss: 0.5828\n",
            "Epoch 11/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 128ms/step - accuracy: 0.8536 - loss: 0.5542 - val_accuracy: 0.8523 - val_loss: 0.5579\n",
            "Epoch 12/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 129ms/step - accuracy: 0.8557 - loss: 0.5508 - val_accuracy: 0.8344 - val_loss: 0.5941\n",
            "Epoch 13/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 128ms/step - accuracy: 0.8549 - loss: 0.5450 - val_accuracy: 0.8540 - val_loss: 0.5507\n",
            "Epoch 14/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 129ms/step - accuracy: 0.8575 - loss: 0.5402 - val_accuracy: 0.8478 - val_loss: 0.5631\n",
            "Epoch 15/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 128ms/step - accuracy: 0.8541 - loss: 0.5386 - val_accuracy: 0.8437 - val_loss: 0.5676\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
            "Test Accuracy: 0.8437, Training Time: 906.69 sec\n",
            "\n",
            "Training model with Filter_size=(3, 3) Regularization=0.01 Batch=128 Optimizer=SGD\n",
            "Epoch 1/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 100ms/step - accuracy: 0.4551 - loss: 4.4899 - val_accuracy: 0.6926 - val_loss: 3.2525\n",
            "Epoch 2/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 100ms/step - accuracy: 0.7042 - loss: 3.0951 - val_accuracy: 0.7313 - val_loss: 2.7262\n",
            "Epoch 3/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 100ms/step - accuracy: 0.7394 - loss: 2.6242 - val_accuracy: 0.7293 - val_loss: 2.3639\n",
            "Epoch 4/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 102ms/step - accuracy: 0.7603 - loss: 2.2621 - val_accuracy: 0.7808 - val_loss: 2.0386\n",
            "Epoch 5/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 99ms/step - accuracy: 0.7762 - loss: 1.9705 - val_accuracy: 0.7499 - val_loss: 1.8292\n",
            "Epoch 6/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 99ms/step - accuracy: 0.7903 - loss: 1.7317 - val_accuracy: 0.7804 - val_loss: 1.6146\n",
            "Epoch 7/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 98ms/step - accuracy: 0.7996 - loss: 1.5371 - val_accuracy: 0.7764 - val_loss: 1.4509\n",
            "Epoch 8/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 98ms/step - accuracy: 0.8044 - loss: 1.3793 - val_accuracy: 0.7991 - val_loss: 1.3136\n",
            "Epoch 9/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 100ms/step - accuracy: 0.8092 - loss: 1.2464 - val_accuracy: 0.8137 - val_loss: 1.1778\n",
            "Epoch 10/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 100ms/step - accuracy: 0.8162 - loss: 1.1320 - val_accuracy: 0.8076 - val_loss: 1.0921\n",
            "Epoch 11/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 100ms/step - accuracy: 0.8207 - loss: 1.0449 - val_accuracy: 0.8216 - val_loss: 1.0030\n",
            "Epoch 12/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 100ms/step - accuracy: 0.8232 - loss: 0.9684 - val_accuracy: 0.8255 - val_loss: 0.9332\n",
            "Epoch 13/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 103ms/step - accuracy: 0.8258 - loss: 0.9055 - val_accuracy: 0.7898 - val_loss: 0.9185\n",
            "Epoch 14/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 102ms/step - accuracy: 0.8304 - loss: 0.8518 - val_accuracy: 0.8306 - val_loss: 0.8330\n",
            "Epoch 15/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 101ms/step - accuracy: 0.8299 - loss: 0.8126 - val_accuracy: 0.8296 - val_loss: 0.8006\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
            "Test Accuracy: 0.8296, Training Time: 705.72 sec\n",
            "\n",
            "Training model with Filter_size=(3, 3) Regularization=0.01 Batch=256 Optimizer=Adam\n",
            "Epoch 1/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 134ms/step - accuracy: 0.6376 - loss: 2.1294 - val_accuracy: 0.7946 - val_loss: 0.8329\n",
            "Epoch 2/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 132ms/step - accuracy: 0.8032 - loss: 0.7821 - val_accuracy: 0.8115 - val_loss: 0.7395\n",
            "Epoch 3/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 131ms/step - accuracy: 0.8207 - loss: 0.6940 - val_accuracy: 0.7950 - val_loss: 0.7090\n",
            "Epoch 4/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 132ms/step - accuracy: 0.8267 - loss: 0.6693 - val_accuracy: 0.8309 - val_loss: 0.6589\n",
            "Epoch 5/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 129ms/step - accuracy: 0.8323 - loss: 0.6497 - val_accuracy: 0.8303 - val_loss: 0.6422\n",
            "Epoch 6/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 130ms/step - accuracy: 0.8361 - loss: 0.6250 - val_accuracy: 0.8281 - val_loss: 0.6445\n",
            "Epoch 7/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 132ms/step - accuracy: 0.8398 - loss: 0.6189 - val_accuracy: 0.8338 - val_loss: 0.6245\n",
            "Epoch 8/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 129ms/step - accuracy: 0.8400 - loss: 0.6034 - val_accuracy: 0.8311 - val_loss: 0.6283\n",
            "Epoch 9/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 130ms/step - accuracy: 0.8429 - loss: 0.5934 - val_accuracy: 0.8289 - val_loss: 0.6234\n",
            "Epoch 10/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 131ms/step - accuracy: 0.8418 - loss: 0.6022 - val_accuracy: 0.8376 - val_loss: 0.6177\n",
            "Epoch 11/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 129ms/step - accuracy: 0.8464 - loss: 0.5867 - val_accuracy: 0.8461 - val_loss: 0.5879\n",
            "Epoch 12/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 129ms/step - accuracy: 0.8468 - loss: 0.5800 - val_accuracy: 0.8397 - val_loss: 0.6017\n",
            "Epoch 13/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 131ms/step - accuracy: 0.8531 - loss: 0.5693 - val_accuracy: 0.8522 - val_loss: 0.5809\n",
            "Epoch 14/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 128ms/step - accuracy: 0.8491 - loss: 0.5700 - val_accuracy: 0.8494 - val_loss: 0.5705\n",
            "Epoch 15/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 130ms/step - accuracy: 0.8560 - loss: 0.5548 - val_accuracy: 0.8366 - val_loss: 0.5894\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
            "Test Accuracy: 0.8366, Training Time: 460.59 sec\n",
            "\n",
            "Training model with Filter_size=(3, 3) Regularization=0.01 Batch=256 Optimizer=SGD\n",
            "Epoch 1/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 101ms/step - accuracy: 0.1997 - loss: 5.0257 - val_accuracy: 0.5185 - val_loss: 4.3483\n",
            "Epoch 2/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 101ms/step - accuracy: 0.5954 - loss: 3.8603 - val_accuracy: 0.6601 - val_loss: 3.3253\n",
            "Epoch 3/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 101ms/step - accuracy: 0.6825 - loss: 3.2064 - val_accuracy: 0.6788 - val_loss: 3.0620\n",
            "Epoch 4/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 101ms/step - accuracy: 0.7172 - loss: 2.9149 - val_accuracy: 0.7107 - val_loss: 2.7860\n",
            "Epoch 5/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 99ms/step - accuracy: 0.7354 - loss: 2.6879 - val_accuracy: 0.7353 - val_loss: 2.5704\n",
            "Epoch 6/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 100ms/step - accuracy: 0.7467 - loss: 2.4855 - val_accuracy: 0.7531 - val_loss: 2.3645\n",
            "Epoch 7/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 101ms/step - accuracy: 0.7554 - loss: 2.3138 - val_accuracy: 0.7651 - val_loss: 2.2036\n",
            "Epoch 8/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 100ms/step - accuracy: 0.7629 - loss: 2.1539 - val_accuracy: 0.7354 - val_loss: 2.1163\n",
            "Epoch 9/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 101ms/step - accuracy: 0.7693 - loss: 2.0179 - val_accuracy: 0.7107 - val_loss: 2.0180\n",
            "Epoch 10/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 99ms/step - accuracy: 0.7789 - loss: 1.8802 - val_accuracy: 0.7484 - val_loss: 1.8543\n",
            "Epoch 11/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 100ms/step - accuracy: 0.7867 - loss: 1.7649 - val_accuracy: 0.7859 - val_loss: 1.7000\n",
            "Epoch 12/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 101ms/step - accuracy: 0.7841 - loss: 1.6685 - val_accuracy: 0.7890 - val_loss: 1.6111\n",
            "Epoch 13/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 102ms/step - accuracy: 0.7926 - loss: 1.5703 - val_accuracy: 0.7962 - val_loss: 1.5159\n",
            "Epoch 14/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 101ms/step - accuracy: 0.7981 - loss: 1.4771 - val_accuracy: 0.7493 - val_loss: 1.5367\n",
            "Epoch 15/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 99ms/step - accuracy: 0.8013 - loss: 1.4037 - val_accuracy: 0.7918 - val_loss: 1.3847\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
            "Test Accuracy: 0.7918, Training Time: 354.95 sec\n",
            "\n",
            "Training model with Filter_size=(5, 5) Regularization=None Batch=128 Optimizer=Adam\n",
            "Epoch 1/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 121ms/step - accuracy: 0.7365 - loss: 0.7745 - val_accuracy: 0.8610 - val_loss: 0.4020\n",
            "Epoch 2/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.8717 - loss: 0.3548 - val_accuracy: 0.8838 - val_loss: 0.3342\n",
            "Epoch 3/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.8942 - loss: 0.2908 - val_accuracy: 0.8874 - val_loss: 0.3142\n",
            "Epoch 4/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.9052 - loss: 0.2598 - val_accuracy: 0.8906 - val_loss: 0.2973\n",
            "Epoch 5/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 119ms/step - accuracy: 0.9125 - loss: 0.2353 - val_accuracy: 0.9065 - val_loss: 0.2648\n",
            "Epoch 6/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.9225 - loss: 0.2132 - val_accuracy: 0.9051 - val_loss: 0.2641\n",
            "Epoch 7/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.9278 - loss: 0.1976 - val_accuracy: 0.9062 - val_loss: 0.2585\n",
            "Epoch 8/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 119ms/step - accuracy: 0.9336 - loss: 0.1807 - val_accuracy: 0.9080 - val_loss: 0.2626\n",
            "Epoch 9/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.9402 - loss: 0.1634 - val_accuracy: 0.9063 - val_loss: 0.2622\n",
            "Epoch 10/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.9427 - loss: 0.1547 - val_accuracy: 0.9093 - val_loss: 0.2617\n",
            "Epoch 11/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 119ms/step - accuracy: 0.9469 - loss: 0.1414 - val_accuracy: 0.9129 - val_loss: 0.2540\n",
            "Epoch 12/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.9531 - loss: 0.1288 - val_accuracy: 0.9130 - val_loss: 0.2603\n",
            "Epoch 13/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.9569 - loss: 0.1164 - val_accuracy: 0.9132 - val_loss: 0.2901\n",
            "Epoch 14/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 119ms/step - accuracy: 0.9596 - loss: 0.1100 - val_accuracy: 0.9170 - val_loss: 0.2793\n",
            "Epoch 15/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.9642 - loss: 0.0973 - val_accuracy: 0.9130 - val_loss: 0.2944\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
            "Test Accuracy: 0.9130, Training Time: 843.08 sec\n",
            "\n",
            "Training model with Filter_size=(5, 5) Regularization=None Batch=128 Optimizer=SGD\n",
            "Epoch 1/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 92ms/step - accuracy: 0.4550 - loss: 1.7732 - val_accuracy: 0.6724 - val_loss: 0.9395\n",
            "Epoch 2/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.7278 - loss: 0.7420 - val_accuracy: 0.7549 - val_loss: 0.6566\n",
            "Epoch 3/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.7664 - loss: 0.6316 - val_accuracy: 0.7775 - val_loss: 0.6109\n",
            "Epoch 4/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.7856 - loss: 0.5777 - val_accuracy: 0.7967 - val_loss: 0.5615\n",
            "Epoch 5/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.8017 - loss: 0.5388 - val_accuracy: 0.8075 - val_loss: 0.5334\n",
            "Epoch 6/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.8192 - loss: 0.4991 - val_accuracy: 0.8205 - val_loss: 0.5005\n",
            "Epoch 7/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.8236 - loss: 0.4839 - val_accuracy: 0.8165 - val_loss: 0.5088\n",
            "Epoch 8/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 91ms/step - accuracy: 0.8347 - loss: 0.4601 - val_accuracy: 0.8310 - val_loss: 0.4788\n",
            "Epoch 9/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.8408 - loss: 0.4415 - val_accuracy: 0.8403 - val_loss: 0.4601\n",
            "Epoch 10/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.8442 - loss: 0.4352 - val_accuracy: 0.8305 - val_loss: 0.4639\n",
            "Epoch 11/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.8510 - loss: 0.4169 - val_accuracy: 0.8438 - val_loss: 0.4390\n",
            "Epoch 12/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 92ms/step - accuracy: 0.8558 - loss: 0.3995 - val_accuracy: 0.8467 - val_loss: 0.4335\n",
            "Epoch 13/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 90ms/step - accuracy: 0.8609 - loss: 0.3904 - val_accuracy: 0.8502 - val_loss: 0.4279\n",
            "Epoch 14/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 93ms/step - accuracy: 0.8641 - loss: 0.3866 - val_accuracy: 0.8568 - val_loss: 0.4005\n",
            "Epoch 15/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 98ms/step - accuracy: 0.8653 - loss: 0.3764 - val_accuracy: 0.8593 - val_loss: 0.3965\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step\n",
            "Test Accuracy: 0.8593, Training Time: 642.88 sec\n",
            "\n",
            "Training model with Filter_size=(5, 5) Regularization=None Batch=256 Optimizer=Adam\n",
            "Epoch 1/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 121ms/step - accuracy: 0.6704 - loss: 0.9398 - val_accuracy: 0.8379 - val_loss: 0.4587\n",
            "Epoch 2/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 122ms/step - accuracy: 0.8491 - loss: 0.4242 - val_accuracy: 0.8571 - val_loss: 0.3962\n",
            "Epoch 3/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 122ms/step - accuracy: 0.8710 - loss: 0.3571 - val_accuracy: 0.8746 - val_loss: 0.3585\n",
            "Epoch 4/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 123ms/step - accuracy: 0.8861 - loss: 0.3124 - val_accuracy: 0.8821 - val_loss: 0.3318\n",
            "Epoch 5/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 121ms/step - accuracy: 0.8950 - loss: 0.2932 - val_accuracy: 0.8903 - val_loss: 0.3056\n",
            "Epoch 6/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 121ms/step - accuracy: 0.9038 - loss: 0.2674 - val_accuracy: 0.8960 - val_loss: 0.2932\n",
            "Epoch 7/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 120ms/step - accuracy: 0.9089 - loss: 0.2496 - val_accuracy: 0.8953 - val_loss: 0.2860\n",
            "Epoch 8/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 125ms/step - accuracy: 0.9120 - loss: 0.2393 - val_accuracy: 0.8991 - val_loss: 0.2790\n",
            "Epoch 9/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 121ms/step - accuracy: 0.9228 - loss: 0.2147 - val_accuracy: 0.8985 - val_loss: 0.2869\n",
            "Epoch 10/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 119ms/step - accuracy: 0.9243 - loss: 0.2086 - val_accuracy: 0.9036 - val_loss: 0.2683\n",
            "Epoch 11/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 119ms/step - accuracy: 0.9300 - loss: 0.1962 - val_accuracy: 0.9062 - val_loss: 0.2622\n",
            "Epoch 12/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 119ms/step - accuracy: 0.9342 - loss: 0.1830 - val_accuracy: 0.9089 - val_loss: 0.2573\n",
            "Epoch 13/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 127ms/step - accuracy: 0.9350 - loss: 0.1773 - val_accuracy: 0.9064 - val_loss: 0.2613\n",
            "Epoch 14/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 132ms/step - accuracy: 0.9411 - loss: 0.1653 - val_accuracy: 0.9072 - val_loss: 0.2656\n",
            "Epoch 15/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 119ms/step - accuracy: 0.9438 - loss: 0.1532 - val_accuracy: 0.9073 - val_loss: 0.2719\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step\n",
            "Test Accuracy: 0.9073, Training Time: 431.11 sec\n",
            "\n",
            "Training model with Filter_size=(5, 5) Regularization=None Batch=256 Optimizer=SGD\n",
            "Epoch 1/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 92ms/step - accuracy: 0.3951 - loss: 2.0015 - val_accuracy: 0.6630 - val_loss: 0.9693\n",
            "Epoch 2/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 92ms/step - accuracy: 0.6640 - loss: 0.9315 - val_accuracy: 0.6870 - val_loss: 0.8553\n",
            "Epoch 3/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 112ms/step - accuracy: 0.7151 - loss: 0.7593 - val_accuracy: 0.7364 - val_loss: 0.7252\n",
            "Epoch 4/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 101ms/step - accuracy: 0.7411 - loss: 0.6877 - val_accuracy: 0.7581 - val_loss: 0.6569\n",
            "Epoch 5/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 113ms/step - accuracy: 0.7619 - loss: 0.6378 - val_accuracy: 0.7651 - val_loss: 0.6225\n",
            "Epoch 6/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 103ms/step - accuracy: 0.7718 - loss: 0.6016 - val_accuracy: 0.7813 - val_loss: 0.6132\n",
            "Epoch 7/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 114ms/step - accuracy: 0.7826 - loss: 0.5798 - val_accuracy: 0.7874 - val_loss: 0.5880\n",
            "Epoch 8/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 99ms/step - accuracy: 0.7998 - loss: 0.5444 - val_accuracy: 0.7755 - val_loss: 0.5989\n",
            "Epoch 9/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 104ms/step - accuracy: 0.8053 - loss: 0.5323 - val_accuracy: 0.8050 - val_loss: 0.5453\n",
            "Epoch 10/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 97ms/step - accuracy: 0.8146 - loss: 0.5101 - val_accuracy: 0.8125 - val_loss: 0.5253\n",
            "Epoch 11/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 103ms/step - accuracy: 0.8215 - loss: 0.4988 - val_accuracy: 0.8136 - val_loss: 0.5190\n",
            "Epoch 12/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 97ms/step - accuracy: 0.8275 - loss: 0.4817 - val_accuracy: 0.8019 - val_loss: 0.5473\n",
            "Epoch 13/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 105ms/step - accuracy: 0.8334 - loss: 0.4671 - val_accuracy: 0.8120 - val_loss: 0.5259\n",
            "Epoch 14/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 93ms/step - accuracy: 0.8343 - loss: 0.4594 - val_accuracy: 0.8109 - val_loss: 0.5230\n",
            "Epoch 15/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 92ms/step - accuracy: 0.8372 - loss: 0.4560 - val_accuracy: 0.8154 - val_loss: 0.4897\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step\n",
            "Test Accuracy: 0.8154, Training Time: 357.40 sec\n",
            "\n",
            "Training model with Filter_size=(5, 5) Regularization=0.01 Batch=128 Optimizer=Adam\n",
            "Epoch 1/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 131ms/step - accuracy: 0.6885 - loss: 1.7787 - val_accuracy: 0.8105 - val_loss: 0.8023\n",
            "Epoch 2/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 128ms/step - accuracy: 0.8194 - loss: 0.7394 - val_accuracy: 0.7962 - val_loss: 0.7240\n",
            "Epoch 3/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 129ms/step - accuracy: 0.8331 - loss: 0.6636 - val_accuracy: 0.8395 - val_loss: 0.6434\n",
            "Epoch 4/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 127ms/step - accuracy: 0.8403 - loss: 0.6332 - val_accuracy: 0.8275 - val_loss: 0.6523\n",
            "Epoch 5/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 146ms/step - accuracy: 0.8439 - loss: 0.6160 - val_accuracy: 0.8310 - val_loss: 0.6318\n",
            "Epoch 6/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 146ms/step - accuracy: 0.8485 - loss: 0.5883 - val_accuracy: 0.8426 - val_loss: 0.6005\n",
            "Epoch 7/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 136ms/step - accuracy: 0.8507 - loss: 0.5810 - val_accuracy: 0.8489 - val_loss: 0.5899\n",
            "Epoch 8/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 129ms/step - accuracy: 0.8556 - loss: 0.5670 - val_accuracy: 0.8412 - val_loss: 0.6017\n",
            "Epoch 9/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 131ms/step - accuracy: 0.8586 - loss: 0.5594 - val_accuracy: 0.8586 - val_loss: 0.5625\n",
            "Epoch 10/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 129ms/step - accuracy: 0.8574 - loss: 0.5514 - val_accuracy: 0.8552 - val_loss: 0.5654\n",
            "Epoch 11/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 129ms/step - accuracy: 0.8560 - loss: 0.5512 - val_accuracy: 0.8546 - val_loss: 0.5560\n",
            "Epoch 12/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 131ms/step - accuracy: 0.8605 - loss: 0.5373 - val_accuracy: 0.8582 - val_loss: 0.5458\n",
            "Epoch 13/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 130ms/step - accuracy: 0.8578 - loss: 0.5355 - val_accuracy: 0.8524 - val_loss: 0.5578\n",
            "Epoch 14/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 131ms/step - accuracy: 0.8625 - loss: 0.5282 - val_accuracy: 0.8548 - val_loss: 0.5536\n",
            "Epoch 15/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 131ms/step - accuracy: 0.8657 - loss: 0.5180 - val_accuracy: 0.8539 - val_loss: 0.5341\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step\n",
            "Test Accuracy: 0.8539, Training Time: 931.22 sec\n",
            "\n",
            "Training model with Filter_size=(5, 5) Regularization=0.01 Batch=128 Optimizer=SGD\n",
            "Epoch 1/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 100ms/step - accuracy: 0.3836 - loss: 4.4613 - val_accuracy: 0.7102 - val_loss: 3.1289\n",
            "Epoch 2/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 111ms/step - accuracy: 0.7124 - loss: 3.0011 - val_accuracy: 0.7430 - val_loss: 2.6416\n",
            "Epoch 3/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 101ms/step - accuracy: 0.7515 - loss: 2.5375 - val_accuracy: 0.7471 - val_loss: 2.3019\n",
            "Epoch 4/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 106ms/step - accuracy: 0.7695 - loss: 2.1960 - val_accuracy: 0.7774 - val_loss: 2.0037\n",
            "Epoch 5/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 105ms/step - accuracy: 0.7854 - loss: 1.9196 - val_accuracy: 0.7915 - val_loss: 1.7614\n",
            "Epoch 6/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 99ms/step - accuracy: 0.7971 - loss: 1.6892 - val_accuracy: 0.7837 - val_loss: 1.5791\n",
            "Epoch 7/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 113ms/step - accuracy: 0.8026 - loss: 1.5010 - val_accuracy: 0.8096 - val_loss: 1.3894\n",
            "Epoch 8/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 122ms/step - accuracy: 0.8091 - loss: 1.3458 - val_accuracy: 0.8147 - val_loss: 1.2572\n",
            "Epoch 9/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 109ms/step - accuracy: 0.8167 - loss: 1.2135 - val_accuracy: 0.8080 - val_loss: 1.1577\n",
            "Epoch 10/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 110ms/step - accuracy: 0.8193 - loss: 1.1113 - val_accuracy: 0.8130 - val_loss: 1.0739\n",
            "Epoch 11/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 120ms/step - accuracy: 0.8250 - loss: 1.0203 - val_accuracy: 0.8131 - val_loss: 1.0014\n",
            "Epoch 12/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 106ms/step - accuracy: 0.8269 - loss: 0.9518 - val_accuracy: 0.8099 - val_loss: 0.9507\n",
            "Epoch 13/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 114ms/step - accuracy: 0.8316 - loss: 0.8848 - val_accuracy: 0.8293 - val_loss: 0.8621\n",
            "Epoch 14/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 118ms/step - accuracy: 0.8388 - loss: 0.8300 - val_accuracy: 0.8125 - val_loss: 0.8618\n",
            "Epoch 15/15\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 115ms/step - accuracy: 0.8419 - loss: 0.7831 - val_accuracy: 0.8354 - val_loss: 0.7822\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step\n",
            "Test Accuracy: 0.8354, Training Time: 774.95 sec\n",
            "\n",
            "Training model with Filter_size=(5, 5) Regularization=0.01 Batch=256 Optimizer=Adam\n",
            "Epoch 1/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 137ms/step - accuracy: 0.6455 - loss: 2.2368 - val_accuracy: 0.7998 - val_loss: 0.9420\n",
            "Epoch 2/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 130ms/step - accuracy: 0.8071 - loss: 0.8593 - val_accuracy: 0.8168 - val_loss: 0.7434\n",
            "Epoch 3/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 130ms/step - accuracy: 0.8311 - loss: 0.7019 - val_accuracy: 0.8229 - val_loss: 0.7026\n",
            "Epoch 4/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 131ms/step - accuracy: 0.8388 - loss: 0.6504 - val_accuracy: 0.8443 - val_loss: 0.6362\n",
            "Epoch 5/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 130ms/step - accuracy: 0.8420 - loss: 0.6265 - val_accuracy: 0.8447 - val_loss: 0.6182\n",
            "Epoch 6/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 133ms/step - accuracy: 0.8446 - loss: 0.6113 - val_accuracy: 0.8404 - val_loss: 0.6185\n",
            "Epoch 7/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 134ms/step - accuracy: 0.8491 - loss: 0.6011 - val_accuracy: 0.8439 - val_loss: 0.6135\n",
            "Epoch 8/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 138ms/step - accuracy: 0.8525 - loss: 0.5837 - val_accuracy: 0.8509 - val_loss: 0.5880\n",
            "Epoch 9/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 145ms/step - accuracy: 0.8534 - loss: 0.5796 - val_accuracy: 0.8331 - val_loss: 0.6278\n",
            "Epoch 10/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 152ms/step - accuracy: 0.8541 - loss: 0.5703 - val_accuracy: 0.8536 - val_loss: 0.5870\n",
            "Epoch 11/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 146ms/step - accuracy: 0.8551 - loss: 0.5662 - val_accuracy: 0.8387 - val_loss: 0.6129\n",
            "Epoch 12/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 156ms/step - accuracy: 0.8527 - loss: 0.5656 - val_accuracy: 0.8512 - val_loss: 0.5727\n",
            "Epoch 13/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 138ms/step - accuracy: 0.8610 - loss: 0.5471 - val_accuracy: 0.8565 - val_loss: 0.5675\n",
            "Epoch 14/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 137ms/step - accuracy: 0.8589 - loss: 0.5480 - val_accuracy: 0.8508 - val_loss: 0.5577\n",
            "Epoch 15/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 131ms/step - accuracy: 0.8603 - loss: 0.5425 - val_accuracy: 0.8567 - val_loss: 0.5505\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step\n",
            "Test Accuracy: 0.8567, Training Time: 487.35 sec\n",
            "\n",
            "Training model with Filter_size=(5, 5) Regularization=0.01 Batch=256 Optimizer=SGD\n",
            "Epoch 1/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 107ms/step - accuracy: 0.2635 - loss: 4.7404 - val_accuracy: 0.6155 - val_loss: 3.7287\n",
            "Epoch 2/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 128ms/step - accuracy: 0.6520 - loss: 3.4654 - val_accuracy: 0.6718 - val_loss: 3.2286\n",
            "Epoch 3/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 111ms/step - accuracy: 0.7076 - loss: 3.0615 - val_accuracy: 0.7290 - val_loss: 2.8730\n",
            "Epoch 4/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 112ms/step - accuracy: 0.7339 - loss: 2.7943 - val_accuracy: 0.7267 - val_loss: 2.6744\n",
            "Epoch 5/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 102ms/step - accuracy: 0.7476 - loss: 2.5815 - val_accuracy: 0.7585 - val_loss: 2.4710\n",
            "Epoch 6/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 120ms/step - accuracy: 0.7605 - loss: 2.3959 - val_accuracy: 0.7537 - val_loss: 2.3140\n",
            "Epoch 7/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 116ms/step - accuracy: 0.7697 - loss: 2.2282 - val_accuracy: 0.7304 - val_loss: 2.1852\n",
            "Epoch 8/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 106ms/step - accuracy: 0.7763 - loss: 2.0843 - val_accuracy: 0.7817 - val_loss: 1.9994\n",
            "Epoch 9/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 103ms/step - accuracy: 0.7844 - loss: 1.9461 - val_accuracy: 0.7516 - val_loss: 1.9317\n",
            "Epoch 10/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 103ms/step - accuracy: 0.7898 - loss: 1.8235 - val_accuracy: 0.7908 - val_loss: 1.7575\n",
            "Epoch 11/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 104ms/step - accuracy: 0.8007 - loss: 1.7013 - val_accuracy: 0.7394 - val_loss: 1.7171\n",
            "Epoch 12/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 106ms/step - accuracy: 0.7949 - loss: 1.6176 - val_accuracy: 0.7884 - val_loss: 1.5853\n",
            "Epoch 13/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 132ms/step - accuracy: 0.8006 - loss: 1.5194 - val_accuracy: 0.7980 - val_loss: 1.4891\n",
            "Epoch 14/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 120ms/step - accuracy: 0.8086 - loss: 1.4289 - val_accuracy: 0.7904 - val_loss: 1.4228\n",
            "Epoch 15/15\n",
            "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 131ms/step - accuracy: 0.8115 - loss: 1.3574 - val_accuracy: 0.8077 - val_loss: 1.3282\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step\n",
            "Test Accuracy: 0.8077, Training Time: 400.66 sec\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train and evaluate different configurations\n",
        "for filter_size in filter_sizes:\n",
        "    for reg in regularizations:\n",
        "        for batch_size in batch_sizes:\n",
        "            for opt_name, optimizer_class in optimizers.items():\n",
        "                title = f\"Filter_size={filter_size} Regularization={reg} Batch={batch_size} Optimizer={opt_name}\"\n",
        "                print(f\"\\nTraining model with {title}\")\n",
        "\n",
        "                model = build_model(filter_size, reg)\n",
        "\n",
        "                optimizer = optimizer_class()  # Create new optimizer instance\n",
        "                model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "                start_time = time.time()\n",
        "                history = model.fit(x_train, y_train, epochs=15, batch_size=batch_size, validation_data=(x_test, y_test))\n",
        "                training_time = time.time() - start_time\n",
        "\n",
        "                # Store results\n",
        "                accuracy_curves[title] = (history.history['accuracy'], history.history['val_accuracy'])\n",
        "                loss_curves[title] = (history.history['loss'], history.history['val_loss'])\n",
        "                cm = confusion_matrix(y_test, np.argmax(model.predict(x_test), axis=1))\n",
        "                confusion_matrices[title] = cm\n",
        "\n",
        "                y_pred = np.argmax(model.predict(x_test), axis=1)\n",
        "                test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "                # # Define file paths inside respective folders\n",
        "                # acc_plot_path = f\"accuracy_curves/accuracy_plot_{title}.png\"\n",
        "                # loss_plot_path = f\"loss_curves/loss_plot_{title}.png\"\n",
        "                # cm_plot_path = f\"confusion_matrices/confusion_matrix_{title}.png\"\n",
        "\n",
        "                acc_plot_path = os.path.join(ROOT_DIR, \"accuracy_curves\", f\"accuracy_plot_{title}.png\")\n",
        "                loss_plot_path = os.path.join(ROOT_DIR, \"loss_curves\", f\"loss_plot_{title}.png\")\n",
        "                cm_plot_path = os.path.join(ROOT_DIR, \"confusion_matrices\", f\"confusion_matrix_{title}.png\")\n",
        "\n",
        "\n",
        "                # Plot Accuracy Curve\n",
        "                plt.figure(figsize=(6, 4))\n",
        "                plt.plot(history.history['accuracy'], label=\"Train Accuracy\")\n",
        "                plt.plot(history.history['val_accuracy'], label=\"Validation Accuracy\", linestyle=\"dashed\")\n",
        "                plt.title(f\"Accuracy Curve\\n{title}\")\n",
        "                plt.xlabel(\"Epochs\")\n",
        "                plt.ylabel(\"Accuracy\")\n",
        "                plt.legend()\n",
        "                plt.savefig(acc_plot_path)\n",
        "                plt.close()\n",
        "\n",
        "                # Plot Loss Curve\n",
        "                plt.figure(figsize=(6, 4))\n",
        "                plt.plot(history.history['loss'], label=\"Train Loss\")\n",
        "                plt.plot(history.history['val_loss'], label=\"Validation Loss\", linestyle=\"dashed\")\n",
        "                plt.title(f\"Loss Curve\\n{title}\")\n",
        "                plt.xlabel(\"Epochs\")\n",
        "                plt.ylabel(\"Loss\")\n",
        "                plt.legend()\n",
        "                plt.savefig(loss_plot_path)\n",
        "                plt.close()\n",
        "\n",
        "                # Plot Confusion Matrix\n",
        "                plt.figure(figsize=(6, 4))\n",
        "                sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(10), yticklabels=range(10))\n",
        "                plt.title(f\"Confusion Matrix\\n{title}\")\n",
        "                plt.xlabel(\"Predicted Label\")\n",
        "                plt.ylabel(\"True Label\")\n",
        "                plt.savefig(cm_plot_path)\n",
        "                plt.close()\n",
        "\n",
        "                # Append results to table\n",
        "                results_table.append([\n",
        "                    filter_size, reg, batch_size, opt_name, test_accuracy, round(training_time, 2),\n",
        "                    acc_plot_path, loss_plot_path, cm_plot_path\n",
        "                ])\n",
        "\n",
        "                print(f\"Test Accuracy: {test_accuracy:.4f}, Training Time: {training_time:.2f} sec\")\n",
        "\n",
        "                del model  # Explicitly delete model after training\n",
        "\n",
        "# Convert results into a DataFrame and print\n",
        "df_results = pd.DataFrame(results_table, columns=[\n",
        "    \"Filter Size\", \"Regularization\", \"Batch Size\", \"Optimizer\", \"Test Accuracy\", \"Execution Time (sec)\",\n",
        "    \"Accuracy Plot\", \"Loss Plot\", \"Confusion Matrix\"\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Save table with graph paths\n",
        "df_results.to_csv(\"training_results_with_graphs.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Jz4n5mWCFGO",
        "outputId": "58e2573e-01fa-4338-8bc3-3197c78ddae8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Training results saved successfully in:- /content/drive/MyDrive/MBM_NN_LAB_6TH_SEM/EXP_5/training_results.csv\n"
          ]
        }
      ],
      "source": [
        "# Define file paths\n",
        "csv_path = os.path.join(ROOT_DIR, \"training_results.csv\")\n",
        "json_path = os.path.join(ROOT_DIR, \"training_results.json\")\n",
        "pickle_path = os.path.join(ROOT_DIR, \"training_results.pkl\")\n",
        "\n",
        "# Save DataFrame as CSV\n",
        "df_results.to_csv(csv_path, index=False)\n",
        "\n",
        "# Save DataFrame as JSON\n",
        "df_results.to_json(json_path, orient=\"records\", indent=4)\n",
        "\n",
        "# Save DataFrame as Pickle (binary format)\n",
        "df_results.to_pickle(pickle_path)\n",
        "\n",
        "print(f\"\\n Training results saved successfully in:- {csv_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItXdZ_E37zGj"
      },
      "source": [
        "## **4.Description of Code**\n",
        "\n",
        "- **Data Loading & Preprocessing:**\n",
        "\n",
        "   - The dataset is loaded using tensorflow.keras.datasets.fashion_mnist.\n",
        "\n",
        "   - Images are normalized to [0,1] range.\n",
        "\n",
        "   - Reshaping is done to match CNN input requirements.\n",
        "\n",
        "- **Model Construction (build_model):**\n",
        "\n",
        "   - A sequential CNN model with configurable filter sizes and regularization.\n",
        "\n",
        "   - Uses Conv2D, MaxPooling2D, Flatten, Dense layers.\n",
        "   \n",
        "   - The model is trained for **15 epochs** using different configurations for hyperparameter tuning with varying\n",
        "     - **Filter Sizes**: (3 x 3) ,(5 x 5)\n",
        "\n",
        "     - **Regularization**: None and 0.01 (L2 Regularization)\n",
        "\n",
        "     - **Batch Sizes**: 128 and 256\n",
        "\n",
        "     - **Optimizers**: Adam and SGD\n",
        "\n",
        "Total of 16 different configuration are trained to find the optimal configuration with significant accuracy.\n",
        "\n",
        "- **Training & Evaluation:**\n",
        "\n",
        "   - Total of 16 different configuration are trained to find the optimal configuration with significant accuracy. using different optimizers (Adam, SGD) and batch sizes.\n",
        "\n",
        "   - Performance is evaluated using accuracy_score and confusion_matrix.\n",
        "\n",
        "- **Visualization:**\n",
        "\n",
        "   - Accuracy and loss curves are plotted using matplotlib.\n",
        "\n",
        "   - Confusion matrices are visualized with seaborn.\n",
        "\n",
        "To evaluate the model for optimal configuaration.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS-vgNob_ard"
      },
      "source": [
        "## **5. Performance Evaluation**\n",
        "The model's performance is evaluated using:\n",
        "- **Test Accuracy:** Measures the classification performance.\n",
        "- **Loss Curve:** Shows training and validation loss trends during training.\n",
        "- **Accuracy Curve:** Tracks the change in accuracy across epochs.\n",
        "- **Confusion Matrix:** Visualizes model predictions compared to actual labels and Highlights classification errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Training Results Summary**\n",
        "\n",
        "This table summarizes different model variations and their performance with visualizations.\n",
        "\n",
### **Training Results Summary**

"This table summarizes different model variations and their performance with visualizations.\n"

         "| Filter Size | Regularization | Batch Size | Optimizer | Test Accuracy | Execution Time (sec) | Accuracy Curve | Loss Curve | Confusion Matrix |\n"
         "|-------------|----------------|------------|-----------|--------------|----------------------|----------------|------------|------------------|\n"
         "| (3, 3)      | None           | 128        | Adam      | 91.67        | 851.03               | ![Accuracy Curve](https://github.com/anki-space/23UADS4106-Ankit-Kumar-NNLAB-2025/raw/main/Exp5/EXP_5_OUTPUT/accuracy_curves/accuracy_plot_Filter_size=(3,%203)%20Regularization=None%20Batch=128%20Optimizer=Adam.png) | ![Loss Curve](https://github.com/anki-space/23UADS4106-Ankit-Kumar-NNLAB-2025/raw/main/Exp5/EXP_5_OUTPUT/loss_curves/loss_plot_Filter_size=(3,%203)%20Regularization=None%20Batch=128%20Optimizer=Adam.png) | ![Confusion Matrix](https://github.com/anki-space/23UADS4106-Ankit-Kumar-NNLAB-2025/raw/main/Exp5/EXP_5_OUTPUT/confusion_matrices/confusion_matrix_Filter_size=(3,%203)%20Regularization=None%20Batch=128%20Optimizer=Adam.png) |\n",
         "| (3, 3)      | None           | 128        | SGD       | 84.71        | 638.19               | ![Accuracy Curve](https://github.com/anki-space/23UADS4106-Ankit-Kumar-NNLAB-2025/raw/main/Exp5/EXP_5_OUTPUT/accuracy_curves/accuracy_plot_Filter_size=(3,%203)%20Regularization=None%20Batch=128%20Optimizer=SGD.png) | ![Loss Curve](https://github.com/anki-space/23UADS4106-Ankit-Kumar-NNLAB-2025/raw/main/Exp5/EXP_5_OUTPUT/loss_curves/loss_plot_Filter_size=(3,%203)%20Regularization=None%20Batch=128%20Optimizer=SGD.png) | ![Confusion Matrix](https://github.com/anki-space/23UADS4106-Ankit-Kumar-NNLAB-2025/raw/main/Exp5/EXP_5_OUTPUT/confusion_matrices/confusion_matrix_Filter_size=(3,%203)%20Regularization=None%20Batch=128%20Optimizer=SGD.png) |\n",
         "| (3, 3)      | None           | 256        | Adam      | 90.50        | 427.83               | ![Accuracy Curve](https://github.com/anki-space/23UADS4106-Ankit-Kumar-NNLAB-2025/raw/main/Exp5/EXP_5_OUTPUT/accuracy_curves/accuracy_plot_Filter_size=(3,%203)%20Regularization=None%20Batch=256%20Optimizer=Adam.png) | ![Loss Curve](https://github.com/anki-space/23UADS4106-Ankit-Kumar-NNLAB-2025/raw/main/Exp5/EXP_5_OUTPUT/loss_curves/loss_plot_Filter_size=(3,%203)%20Regularization=None%20Batch=256%20Optimizer=Adam.png) | ![Confusion Matrix](https://github.com/anki-space/23UADS4106-Ankit-Kumar-NNLAB-2025/raw/main/Exp5/EXP_5_OUTPUT/confusion_matrices/confusion_matrix_Filter_size=(3,%203)%20Regularization=None%20Batch=256%20Optimizer=Adam.png) |\n",
         "| (3, 3)      | None           | 256        | SGD       | 82.46        | 322.94               | ![Accuracy Curve](https://github.com/anki-space/23UADS4106-Ankit-Kumar-NNLAB-2025/raw/main/Exp5/EXP_5_OUTPUT/accuracy_curves/accuracy_plot_Filter_size=(3,%203)%20Regularization=None%20Batch=256%20Optimizer=SGD.png) | ![Loss Curve](https://github.com/anki-space/23UADS4106-Ankit-Kumar-NNLAB-2025/raw/main/Exp5/EXP_5_OUTPUT/loss_curves/loss_plot_Filter_size=(3,%203)%20Regularization=None%20Batch=256%20Optimizer=SGD.png) | ![Confusion Matrix](https://github.com/anki-space/23UADS4106-Ankit-Kumar-NNLAB-2025/raw/main/Exp5/EXP_5_OUTPUT/confusion_matrices/confusion_matrix_Filter_size=(3,%203)%20Regularization=None%20Batch=256%20Optimizer=SGD.png) |\n",
         "| (3, 3)      | 0.01           | 128        | Adam      | 84.37        | 906.69               | ![Accuracy Curve](https://github.com/anki-space/23UADS4106-Ankit-Kumar-NNLAB-2025/raw/main/Exp5/EXP_5_OUTPUT/accuracy_curves/accuracy_plot_Filter_size=(3,%203)%20Regularization=0.01%20Batch=128%20Optimizer=Adam.png) | ![Loss Curve](https://github.com/anki-space/23UADS4106-Ankit-Kumar-NNLAB-2025/raw/main/Exp5/EXP_5_OUTPUT/loss_curves/loss_plot_Filter_size=(3,%203)%20Regularization=0.01%20Batch=128%20Optimizer=Adam.png) | ![Confusion Matrix](https://github.com/anki-space/23UADS4106-Ankit-Kumar-NNLAB-2025/raw/main/Exp5/EXP_5_OUTPUT/confusion_matrices/confusion_matrix_Filter_size=(3,%203)%20Regularization=0.01%20Batch=128%20Optimizer=Adam.png) |\n",
        



         "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **6.Conclusion**\n",
        "\n",
        "From the above summary of graph we can see that\n",
        "1. **Use Adam instead of SGD** for Fashion MNIST.  \n",
        "2. **Adding L2** Regularization (0.01) **reduces accuracy** compared to no regularization.\n",
        "3. **Smaller filters (3x3) work better** for this dataset .\n",
        "   - Example:\n",
        "      - (3,3) | No Regularization | Adam | Batch 128 → **91.67%**  \n",
        "      - (5,5) | No Regularization | Adam | 128 batch → **91.30%**\n",
        "4. **Batch size 128 gives the best balance between accuracy and training speed.**  \n",
        "    - Example:\n",
        "      - (3,3) | No Regularization | Adam | Batch 128 → **91.67%** and **851.06s** \n",
        "      - (3,3) | No Regularization | Adam | Batch 256 → **90.50%** and **431.11s** \n",
        "      - However, **Batch 256** reduces execution time significantly (~50% faster).  \n",
        "      - There’s a trade-off between accuracy and training speed.\n",
        "\n",
        "      \n",
        "**Best-performing model:**  \n",
        "   - **Filter: (3,3), No Regularization, Batch 128, Adam Optimizer → 91.67% Accuracy**  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP995jBu_ym5"
      },
      "source": [
        "## **7. My Comments**\n",
        "\n",
        "### Limitations:\n",
        "- Training is done for only 15 epochs due to time constraints, which may not be optimal.\n",
        "- The dataset is relatively simple; a more complex dataset would provide better insights.\n",
        "- The model architecture is basic; additional layers or augmentation could improve performance.\n",
        "\n",
        "### Scope for Improvement:\n",
        "- Experiment with more hyperparameters like activation functions,number conv2d layers.\n",
        "- Increase training epochs and use learning rate scheduling.\n",
        "- Using  data augmentation techniques to improve generalization.\n",
        "- Expermenting with different pre built cnn architecture like ***ResNet** can enhance the accuracy and time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HCLSrG6c12R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
